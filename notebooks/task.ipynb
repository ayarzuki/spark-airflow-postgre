{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47e3301f-eacf-4570-94e7-96c4449a34a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.functions import to_timestamp,col,when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "503e840a-d94d-48b4-b3e7-3f5d36d233ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33abb2ef-a53b-4d81-8cf7-af2ddc8d4ee6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv_path = Path('/resources/.env')\n",
    "load_dotenv(dotenv_path=dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d532e0e0-e831-416e-aae4-58e953d90bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "postgres_host = os.getenv('POSTGRES_CONTAINER_NAME')\n",
    "postgres_db = os.getenv('POSTGRES_DB')\n",
    "postgres_user = os.getenv('POSTGRES_USER')\n",
    "postgres_password = os.getenv('POSTGRES_PASSWORD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "473aff82-a147-45be-9b2e-3e07c6d3d3b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sparkcontext = pyspark.SparkContext.getOrCreate(conf=(\n",
    "        pyspark\n",
    "        .SparkConf()\n",
    "        .setAppName('Dibimbing')\n",
    "        .setMaster('local')\n",
    "        .set(\"spark.jars\", \"/opt/postgresql-42.2.18.jar\")\n",
    "    ))\n",
    "sparkcontext.setLogLevel(\"WARN\")\n",
    "\n",
    "spark = pyspark.sql.SparkSession(sparkcontext.getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dccd8594-23d5-4e4e-a70a-59cac5278d56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jdbc_url = f'jdbc:postgresql://{postgres_host}/{postgres_db}'\n",
    "jdbc_properties = {\n",
    "    'user': postgres_user,\n",
    "    'password': postgres_password,\n",
    "    'driver': 'org.postgresql.Driver',\n",
    "    'stringtype': 'unspecified'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "602751f2-f7a9-411f-95f3-7fa1a1844b00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retail_df = spark.read.jdbc(\n",
    "    jdbc_url,\n",
    "    'public.retail',\n",
    "    properties=jdbc_properties\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ebc9142-5780-4c67-9ceb-49a22677fbc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+\n",
      "|invoiceno|stockcode|         description|quantity|invoicedate|unitprice|customerid|       country|\n",
      "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6| 2010-12-01|     2.55|     17850|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6| 2010-12-01|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8| 2010-12-01|     2.75|     17850|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6| 2010-12-01|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6| 2010-12-01|     3.39|     17850|United Kingdom|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2| 2010-12-01|     7.65|     17850|United Kingdom|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6| 2010-12-01|     4.25|     17850|United Kingdom|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6| 2010-12-01|     1.85|     17850|United Kingdom|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6| 2010-12-01|     1.85|     17850|United Kingdom|\n",
      "|   536367|    84879|ASSORTED COLOUR B...|      32| 2010-12-01|     1.69|     13047|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retail_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8480e89-b287-4fd0-973f-d6e336a181d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|stockcode|count|\n",
      "+---------+-----+\n",
      "|    22728|  810|\n",
      "|    21889|  607|\n",
      "|   90210B|    7|\n",
      "|    21259|  296|\n",
      "|    21894|  135|\n",
      "|    21452|  200|\n",
      "|    22121|  141|\n",
      "|    90022|   21|\n",
      "|    21249|  119|\n",
      "|    90143|   22|\n",
      "|    84881|    8|\n",
      "|    21248|   68|\n",
      "|    22254|   61|\n",
      "|    20868|   46|\n",
      "|    21331|    8|\n",
      "|   90197B|   27|\n",
      "|    22596|  274|\n",
      "|   90026D|    3|\n",
      "|   90177A|   10|\n",
      "|   84899F|    1|\n",
      "+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simple aggregation (example: count by stock code)\n",
    "aggregated_df = retail_df.groupBy(\"stockcode\").count()\n",
    "\n",
    "# Output (example: write to console and CSV)\n",
    "aggregated_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "345c6a1e-8445-40a5-aa82-94afc0d8f259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Churn and return (or re-engagement) analysis is essential for understanding customer behavior over time. \n",
    "# Using the given data, we can perform such an analysis by observing purchase patterns of each customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a71deb81-053d-4530-9ef9-c6ad3c69d6b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Assuming data is loaded into a DataFrame named retail_df\n",
    "retail_df = retail_df.withColumn(\"invoicedate\", F.to_date(\"invoicedate\", \"yyyy-MM-dd\"))\n",
    "\n",
    "# Calculate the maximum purchase date for each customer\n",
    "max_purchase_date = retail_df.groupBy(\"customerid\").agg(F.max(\"invoicedate\").alias(\"last_purchase_date\"))\n",
    "\n",
    "# Let's assume a customer who hasn't made a purchase in the last 30 days is considered churned\n",
    "churned_customers = max_purchase_date.filter(F.datediff(F.current_date(), \"last_purchase_date\") > 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "004373ed-ddb1-4240-972a-17a1546a9536",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('invoiceno', 'string'), ('stockcode', 'string'), ('description', 'string'), ('quantity', 'int'), ('invoicedate', 'date'), ('unitprice', 'double'), ('customerid', 'string'), ('country', 'string')]\n"
     ]
    }
   ],
   "source": [
    "print(retail_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8acb6f4-c66d-4af0-95b8-cef953d41049",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of churned customers: 4373\n"
     ]
    }
   ],
   "source": [
    "# For return analysis, we would observe these churned customers in the subsequent period. \n",
    "# This involves more complex logic such as observing their next purchase date after the churn date, etc.\n",
    "\n",
    "# For this example, let's just count the number of churned customers\n",
    "churned_count = churned_customers.count()\n",
    "\n",
    "print(f\"Number of churned customers: {churned_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "794f3200-a220-42bd-8964-e593d35e28f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+\n",
      "|stockcode|total_quantity|\n",
      "+---------+--------------+\n",
      "|    20868|           458|\n",
      "|    22728|          5323|\n",
      "|    21889|          6377|\n",
      "|   90197B|            35|\n",
      "|    21249|           724|\n",
      "|    22121|           305|\n",
      "|    21259|          1117|\n",
      "|    21248|           186|\n",
      "|    22254|           657|\n",
      "|    21452|           789|\n",
      "|    21894|           557|\n",
      "|    84881|             0|\n",
      "|    22596|          3477|\n",
      "|   90026D|             3|\n",
      "|    90143|            31|\n",
      "|   90177A|             8|\n",
      "|    90022|            20|\n",
      "|   84899F|            -5|\n",
      "|   85132b|             9|\n",
      "|    21331|            12|\n",
      "+---------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregation\n",
    "# To get the total quantity of each product sold:\n",
    "\n",
    "from pyspark.sql.functions import sum\n",
    "\n",
    "aggregated_df = retail_df.groupBy(\"stockcode\").agg(sum(\"quantity\").alias(\"total_quantity\"))\n",
    "aggregated_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f834433e-dd40-47c4-bda6-70a1343db9b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+----+\n",
      "|invoiceno|stockcode|         description|quantity|invoicedate|unitprice|customerid|       country|rank|\n",
      "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+----+\n",
      "|   581483|    23843|PAPER CRAFT , LIT...|   80995| 2011-12-09|     2.08|     16446|United Kingdom|   1|\n",
      "|   541431|    23166|MEDIUM CERAMIC TO...|   74215| 2011-01-18|     1.04|     12346|United Kingdom|   2|\n",
      "|   578841|    84826|ASSTD DESIGN 3D P...|   12540| 2011-11-25|      0.0|     13256|United Kingdom|   3|\n",
      "|   542504|    37413|                null|    5568| 2011-01-28|      0.0|      null|United Kingdom|   4|\n",
      "|   573008|    84077|WORLD WAR 2 GLIDE...|    4800| 2011-10-27|     0.21|     12901|United Kingdom|   5|\n",
      "|   554868|    22197|SMALL POPCORN HOLDER|    4300| 2011-05-27|     0.72|     13135|United Kingdom|   6|\n",
      "|   556231|   85123A|                   ?|    4000| 2011-06-09|      0.0|      null|United Kingdom|   7|\n",
      "|   544612|    22053|EMPIRE DESIGN ROS...|    3906| 2011-02-22|     0.82|     18087|United Kingdom|   8|\n",
      "|   560599|    18007|ESSENTIAL BALM 3....|    3186| 2011-07-19|     0.06|     14609|United Kingdom|   9|\n",
      "|   550461|    21108|FAIRY CAKE FLANNE...|    3114| 2011-04-18|      2.1|     15749|United Kingdom|  10|\n",
      "|   540815|    21108|FAIRY CAKE FLANNE...|    3114| 2011-01-11|      2.1|     15749|United Kingdom|  10|\n",
      "|   560040|    23343| came coded as 20713|    3100| 2011-07-14|      0.0|      null|United Kingdom|  12|\n",
      "|   546139|    84988|                   ?|    3000| 2011-03-09|      0.0|      null|United Kingdom|  13|\n",
      "|   573995|    16014|SMALL CHINESE STY...|    3000| 2011-11-02|     0.32|     16308|United Kingdom|  13|\n",
      "|   562439|    84879|ASSORTED COLOUR B...|    2880| 2011-08-04|     1.45|     12931|United Kingdom|  15|\n",
      "|   536830|    84077|WORLD WAR 2 GLIDE...|    2880| 2010-12-02|     0.18|     16754|United Kingdom|  15|\n",
      "|   554272|    21977|PACK OF 60 PINK P...|    2700| 2011-05-23|     0.42|     12901|United Kingdom|  17|\n",
      "|   543057|    84077|WORLD WAR 2 GLIDE...|    2592| 2011-02-03|     0.21|     16333|United Kingdom|  18|\n",
      "|   542505|   79063D|                null|    2560| 2011-01-28|      0.0|      null|United Kingdom|  19|\n",
      "|   543669|    22693|GROW A FLYTRAP OR...|    2400| 2011-02-11|     0.94|     16029|United Kingdom|  20|\n",
      "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rank\n",
    "# We want to rank each product based on the quantity sold:\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank\n",
    "\n",
    "windowSpec = Window.orderBy(retail_df[\"quantity\"].desc())\n",
    "\n",
    "ranked_df = retail_df.withColumn(\"rank\", rank().over(windowSpec))\n",
    "ranked_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
